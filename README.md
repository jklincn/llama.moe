# llama.moe

Optimized inference of MoE models based on llama.cpp, with dynamic expert offloading.

# Run

```
git clone --recurse-submodules https://github.com/jklincn/llama.moe.git
cd llama.moe
pip install -r requirements.txt
```