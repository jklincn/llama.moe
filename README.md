# llama.moe

Optimized inference of MoE models based on llama.cpp, with dynamic expert offloading.

## Get Started

### Installation dependencies

```
sudo apt update
sudo apt install build-essential cmake ccache libcurl4-openssl-dev ninja-build


```

### Build

```
git clone --recurse-submodules https://github.com/jklincn/llama.moe.git
cd llama.moe
scripts/build.sh -r

uv sync
```

### Run

```
TODO
```

## Dev Installation

```
uv sync --extra dev
```

